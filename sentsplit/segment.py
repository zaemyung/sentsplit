from __future__ import annotations

import math
import os
import pprint
from pathlib import Path 
from copy import deepcopy
from typing import Any, Optional, Union

# Removed
# import pkg_resources
# Reason: deprecation warnings

import pycrfsuite
import regex as re
from loguru import logger

from sentsplit import config, regexes
from sentsplit.regexes import Regex
from sentsplit.train import _PUNCTUATIONS, _sample_to_features
from sentsplit.utils import split_keep_multiple_separators


class SentSplit:
    """Sentence segmentation using CRF models with configurable rules.
    
    Supports multiple languages with built-in models or custom trained models
    for unsupported languages.
    """
    def __init__(self, lang: str, **kwargs: Any) -> None:
        """Initialize SentSplit for a given language.
    
        :param lang: ISO language code (e.g., 'en', 'fr', 'ko') or custom language
        :param kwargs: Configuration overrides including 'model' path for custom models
        
        :raises FileNotFoundError: If model file does not exist
        :raises ValueError: If required parameters are missing
        """
        self.lang = lang
    
        # Step 1: Get appropriate config and is_builtin_model
        try:
            default_config = deepcopy(getattr(config, f"{self.lang}_config"))
            is_builtin_model = True
        except AttributeError:
            default_config = deepcopy(getattr(config, "base_config"))
            is_builtin_model = False
            
        # Step 2: Extract model path if explicitly provided
        model_path = None
        if 'model' in kwargs:
            model_path = Path(str(kwargs.pop('model')))
        elif 'model' in default_config and default_config['model']:
            model_path = Path(str(default_config["model"]))
        else:
            raise ValueError(
                "Model path is required. "
                "For unsupported languages, provide 'model' parameter. "
            )
            
        # Step 3: Override config arguments (excluding model since we handled it above)
        for k, v in kwargs.items():
            if k not in default_config and k != "model":
                logger.warning(f"`{k}` not in config, skipped")
                continue
            default_config[k] = v

        self.config = default_config    
        
        # Step 4: Validate model path
        if is_builtin_model:
            # Built-in model - resolve relative to package directory
            package_root = Path(__file__).parent
            model_path = package_root / model_path
            
            if model_path.is_file():
                self.config["model"] = str(model_path) # Convert it to str if it is Path object
            else:
                raise FileNotFoundError(f"Built-in model not found: {model_path}")
        else:
            if model_path.is_file():
                self.config["model"] = str(model_path)
                logger.info(f"Using custom model: {model_path}")
            else:
                raise FileNotFoundError(f"Model file not found: {model_path}")
                
            
        # Load tagger
        self.tagger = self._load_model(self.config["model"])
       
       # Fill regexes
        self._fill_regexes()
    
        config_string = pprint.pformat(self.config, indent=2)
        logger.info(f"SentSplit for {self.lang.upper()} loaded:\n{config_string}")
        
    def __enter__(self):
        return self

    def __exit__(self, exception_type, exception_value, traceback):
        self.close()

    @staticmethod
    def _load_model(model_path: str) -> pycrfsuite.Tagger:
        tagger = pycrfsuite.Tagger()
        tagger.open(model_path)
        return tagger

    def _fill_regexes(self) -> None:
        """
        Retrieve actual regexes from `regexes.py` by their `name`s if not given
        """
        for rgx_index, rgx in enumerate(self.config["segment_regexes"]):
            if "regex" not in rgx:
                self.config["segment_regexes"][rgx_index] = getattr(regexes, rgx["name"])
        for rgx_index, rgx in enumerate(self.config["prevent_regexes"]):
            if "regex" not in rgx:
                self.config["prevent_regexes"][rgx_index] = getattr(regexes, rgx["name"])

    def segment(self, string: Union[str, list[str]], strip_spaces: Optional[bool] = None) -> list[str]:
        if strip_spaces is None:
            strip_spaces = self.config["strip_spaces"]
        else:
            assert isinstance(strip_spaces, bool), "`strip_spaces` must be a boolean value"

        # for string input
        if isinstance(string, str):
            result = self._segment(string, strip_spaces)
        # for list input
        else:
            assert isinstance(string, list)
            result = [self._segment(t, strip_spaces) for t in string]
        return result

    def _segment(self, original_string: str, strip_spaces: bool) -> list[str]:
        """This method deals with a single string"""
        # initially segment by line feeds
        strings = split_keep_multiple_separators(original_string, ["\n"])

        # list of original characters per string
        chars_strings = []
        # list of character n-gram features per string
        features_strings = []
        # list of tuples(matched_spaces, start_ind, end_ind) per string
        multiple_spaces_positions_strings = []

        for string in strings:
            # keep the original characters per string
            chars_strings.append([c for c in string])
            if self.config["handle_multiple_spaces"]:
                # replace multiple spaces with a single space for better segmentation by CRF model
                (
                    preprocessed_string,
                    multiple_spaces_positions,
                ) = SentSplit._substitute_multiple_spaces(string)
                multiple_spaces_positions_strings.append(multiple_spaces_positions)
                # convert the string into character n-gram features
                features_strings.append(_sample_to_features([c for c in preprocessed_string], self.config["ngram"]))
            else:
                # convert the string into character n-gram features
                features_strings.append(_sample_to_features([c for c in string], self.config["ngram"]))

        # tag strings
        y_tags_strings = [self.tagger.tag(f_s) for f_s in features_strings]

        if self.config["handle_multiple_spaces"]:
            # adjust y_tags_strings to account for the removed multiple spaces
            y_tags_strings = SentSplit._adjust_tags_for_multiple_spaces(
                y_tags_strings, multiple_spaces_positions_strings
            )

        y_tags_strings = SentSplit._tag_segment_regexes(y_tags_strings, strings, self.config["segment_regexes"])
        y_tags_strings = SentSplit._tag_prevent_regexes(
            y_tags_strings,
            strings,
            self.config["prevent_regexes"],
            self.config["maxcut"],
            self.config["prevent_word_split"],
        )
        results = SentSplit._segment_by_char_tag(
            chars_strings,
            y_tags_strings,
            strip_spaces,
            self.config["maxcut"],
            self.config["mincut"],
        )
        return results

    @staticmethod
    def _substitute_multiple_spaces(line: str) -> tuple[str, list[tuple[int, int]]]:
        """
        Substitute multiple spaces with a single space and record their indices so that they can be restored later
        multiple_spaces_positions: [(start_ind, end_ind), ..]
        """
        rgx_multiple_spaces = r"(\s{2,})"
        multiple_spaces_positions = [(m.start(0), m.end(0)) for m in re.finditer(rgx_multiple_spaces, line)]
        if len(multiple_spaces_positions) > 0:
            line = re.sub(rgx_multiple_spaces, " ", line)
        return line, multiple_spaces_positions

    @staticmethod
    def _adjust_tags_for_multiple_spaces(
        y_tags_strings: list[list[str]],
        multiple_spaces_positions_strings: list[list[tuple[int, int]]],
    ) -> list[list[str]]:
        """
        So far y_tags_strings contains labels (tags) for the multiple-space-substituted strings
        This method adds back (`len_matched_spaces` - 1) 'O' tags after the substituted single space to restore original strings
        Note that `start_char_ind` and `end_char_ind` are character-level indices of the original strings
        Example:
            Input:
                (original) string: 'It is good.   Ha'
                preprocessed_string: 'It is good. Ha'  (after _substitute_multiple_spaces)
                y_tags_string: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'EOS', 'O', 'O','O']
            Returns:
                (Restores the three spaces after '~ good.'
                y_tags_string: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'EOS', 'O', 'O', 'O', 'O','O']
        """
        assert len(y_tags_strings) == len(multiple_spaces_positions_strings)
        for string_index, multiple_spaces_positions in enumerate(multiple_spaces_positions_strings):
            y_tags = y_tags_strings[string_index]
            for start_char_ind, end_char_ind in multiple_spaces_positions:
                len_matched_spaces = end_char_ind - start_char_ind
                # y_tags already contains an 'O' for one space, hence subtract 1
                o_tags_for_matched_spaces = ["O"] * (len_matched_spaces - 1)
                # insert 'O's after the index of the substituted single space
                y_tags = y_tags[: start_char_ind + 1] + o_tags_for_matched_spaces + y_tags[start_char_ind + 1 :]
            y_tags_strings[string_index] = y_tags
        return y_tags_strings

    @staticmethod
    def _tag_segment_regexes(
        y_tags_strings: list[list[str]], strings: list[str], segment_regexes: list[Regex]
    ) -> list[list[str]]:
        """
        Label either the start or end indices of the matched regex patterns with 'EOS'
        @param segment_regexes: [{'regex': '<pattern>', 'at': <'end' or 'start'>}, ..]
        """
        for string_index, string in enumerate(strings):
            assert len(string) == len(y_tags_strings[string_index])
            for rgx in segment_regexes:
                for matched_position in re.finditer(rgx["regex"], string):
                    start = matched_position.start(0)
                    end = matched_position.end(0) - 1
                    if rgx["at"] == "start":
                        y_tags_strings[string_index][start] = "EOS"
                    else:
                        y_tags_strings[string_index][end] = "EOS"
        return y_tags_strings

    @staticmethod
    def _tag_prevent_regexes(
        y_tags_strings: list[list[str]],
        strings: list[str],
        prevent_regexes: list[Regex],
        maxcut: int,
        prevent_word_split: bool,
    ) -> list[list[str]]:
        """
        Remove 'EOS' label for characters that are matched by prevent_regexes
        and prevent these characters from being cut due to maxcut
        @param prevent_regexes: [{'regex': '<pattern>'}, ..]
        """

        def _tag_prevent_word_split(y_tags: list[str], curr_string: str) -> list[str]:
            """Prevent segmentation occurring in the middle of a word"""
            assert isinstance(curr_string, str)
            for i, tag in enumerate(y_tags[:-1]):
                if tag != "EOS":
                    continue
                char = curr_string[i]
                if char not in _PUNCTUATIONS and not char.isspace() and not curr_string[i + 1].isspace():
                    y_tags[i] = "O"
            return y_tags

        def _get_last_segmented_index(labels: list[str], pivot: int) -> int:
            """Return the closest previously cut index to pivot"""
            if pivot < 1:
                return -1
            for index in range(pivot - 1, -1, -1):
                if labels[index] == "EOS":
                    return index
            return -1

        for string_index, string in enumerate(strings):
            assert len(string) == len(y_tags_strings[string_index])
            y_tags_string = y_tags_strings[string_index]
            if prevent_word_split:
                y_tags_string = _tag_prevent_word_split(y_tags_string, string)
            for rgx in prevent_regexes:
                for matched_position in re.finditer(rgx["regex"], string):
                    start = matched_position.start(0)
                    end = matched_position.end(0) - 1
                    # add 'O' at matched positions
                    for pos in range(start, end + 1):
                        y_tags_string[pos] = "O"

                    # make sure this pattern is not maxcut later by segmenting before the pattern
                    if end < maxcut:
                        # no need to check if the pattern falls within the maxcut
                        continue
                    last_segmented_index = _get_last_segmented_index(y_tags_string, start)
                    last_segmented_plus_one = last_segmented_index + 1
                    length_to_cover = end - last_segmented_plus_one + 1  # inclusive
                    num_cuts = math.floor(length_to_cover / maxcut)
                    if num_cuts < 1:
                        num_cuts = 1
                    maxcutted_length = num_cuts * maxcut - 1
                    next_maxcut_pos = last_segmented_plus_one + maxcutted_length
                    # cut before the pattern if the next_maxcut_pos falls within the pattern
                    if start <= next_maxcut_pos < end and start - 1 > 0:
                        y_tags_string[start - 1] = "EOS"

            y_tags_strings[string_index] = y_tags_string
        return y_tags_strings

    @staticmethod
    def _segment_by_char_tag(
        chars_strings: list[list[str]],
        y_tags_strings: list[list[str]],
        strip_spaces: bool,
        maxcut: int,
        mincut: int,
    ) -> list[str]:
        """
        Loop through character-level tags and segment when 'EOS' and other conditions are met
        :param chars_strings: list of lines where each line consists of characters
        :param y_tags_strings: list of lines where each line consists of tags which are either 'O' or 'EOS'
        """

        def _check_and_add_sentence(sent: str, str_len: int, cur_ind: int, is_leftover: bool = False) -> bool:
            """
            Check if the given `sent` can be added to `results`.
            If so, add to `results` and return `True`; otherwise, return `False`
            """
            if len(sent) <= mincut:
                if not is_leftover:
                    return False
                # if it is a leftover, but also an empty string, then don't add
                elif len(sent) <= 0:
                    return False
            if strip_spaces:
                sent = sent.strip()
            if len(sent) <= 0:
                return False
            # if the no. of remaining characters are less than mincut, don't add
            if not is_leftover and (str_len - cur_ind) <= mincut:
                return False
            results.append(sent)
            return True

        def _segment_maxcut_string(sent: str) -> str:
            """
            Heuristically segment a maxcut string into two, add the first half to `results`, and return the remaining half.
            A list of heuristic regexes are applied to `sent` in decreasing order of importance.
            As soon as a matching is found, the sentence is segmented.
            """
            rgx_punctuation_and_closing = r'(?<=[\.。︀?？!！…])[\'"’”❜❞›»❯」』)）\]］】〟]'
            rgx_closing_and_punctuation = r'(?<=[\'"’”❜❞›»❯」』)）\]］】〟])[\.。︀?？!！…]'
            rgx_space_and_dash = r"(?<=\s)\p{Pd}"
            rgx_colon = r"[:﹕：;﹔；؛⁏]"
            rgx_not_space_and_closing_and_space = r'(?<=[^\s])[\'"’”❜❞›»❯」』)）\]］】〟](?=\s)'
            rgx_comma = r"[,，﹐]"
            rgx_closing = r"[’”❜❞›»❯」』)）\]］】〟]"
            rgx_whitespace = r"\s"
            heuristics = [
                rgx_punctuation_and_closing,
                rgx_closing_and_punctuation,
                rgx_space_and_dash,
                rgx_colon,
                rgx_not_space_and_closing_and_space,
                rgx_comma,
                rgx_closing,
                rgx_whitespace,
            ]
            for heu in heuristics:
                for match in re.finditer(heu, sent):
                    assert match.end() - match.start() == 1
                    first_half = sent[: match.end()]
                    if _check_and_add_sentence(first_half, len(sent), len(first_half)):
                        return sent[match.end() :]
            if _check_and_add_sentence(sent, string_length, current_index, is_leftover=True):
                return ""
            raise RuntimeError(f"Cannot segment maxcut string: {sent}")

        results = []
        for char_string, tags in zip(chars_strings, y_tags_strings):
            sentence = ""
            string_length = len(char_string)
            if string_length < 1 and len(char_string) > 0:
                results.append(char_string)
                continue
            for current_index, (current_character, tag) in enumerate(zip(char_string, tags)):
                if len(sentence) >= maxcut:
                    sentence = _segment_maxcut_string(sentence)
                if tag == "EOS":
                    sentence += current_character
                    if _check_and_add_sentence(sentence, string_length, current_index):
                        sentence = ""
                else:
                    sentence += current_character
            if _check_and_add_sentence(sentence, string_length, current_index, is_leftover=True):
                sentence = ""
        return results

    def close(self):
        if self.tagger is not None:
            return self.tagger.close()
